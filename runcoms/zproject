#
# Project related configurations
#

#====== MLIR ======#

mlir-cmake() {
  if (( $# < 3 ))
  then
    echo "usage: $0 <source-dir> <target-dir> <build-type>"
    return 1
  fi

  SOURCE_DIR=$1; shift
  TARGET_DIR=$1; shift
  BUILD_TYPE=$1; shift

  if [[ "$(uname)" == "Darwin" ]]; then
    LLVM_LLD=""
  else
    LLVM_LLD="-DLLVM_ENABLE_LLD=ON"
  fi

  cmake -GNinja \
    -S ${SOURCE_DIR} -B ${TARGET_DIR} \
    -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
    -DCMAKE_C_COMPILER=$(which clang) -DCMAKE_CXX_COMPILER=$(which clang++) \
    ${LLVM_LLD} \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \
    -DLLVM_ENABLE_PROJECTS="llvm;mlir" \
    -DLLVM_TARGETS_TO_BUILD="host;AMDGPU;NVPTX" \
    -DMLIR_ENABLE_BINDINGS_PYTHON=ON -DPython3_EXECUTABLE="$(which python)" \
    -DLLVM_ENABLE_ASSERTIONS=ON \
    -DMLIR_ENABLE_VULKAN_RUNNER=ON \
    -DMLIR_ENABLE_SPIRV_CPU_RUNNER=ON \
    -DLLVM_BUILD_EXAMPLES=ON "$@"
}

#====== IREE ======#

iree-cmake() {
  if (( $# < 3 ))
  then
    echo "usage: $0 <source-dir> <target-dir> <build-type>"
    return 1
  fi

  SOURCE_DIR=$1; shift
  TARGET_DIR=$1; shift
  BUILD_TYPE=$1; shift

  if [[ "$(uname)" == "Darwin" ]]; then
    IREE_LLD=""
    IREE_THIN_ARCHIVES=""
  else
    IREE_LLD="-DIREE_ENABLE_LLD=ON"
    IREE_THIN_ARCHIVES="-DIREE_ENABLE_THIN_ARCHIVES=ON"
  fi

  if [[ $(command -v ccache) ]]; then
    CCACHE_CC="-DCMAKE_C_COMPILER_LAUNCHER=ccache"
    CCACHE_CXX="-DCMAKE_CXX_COMPILER_LAUNCHER=ccache"
  else
    CCACHE_CC=""
    CCACHE_CXX=""
  fi

  if [[ $(command -v nvidia-smi) ]]; then
    CUDA_TARGET="-DIREE_TARGET_BACKEND_CUDA=ON"
    CUDA_DRIVER="-DIREE_HAL_DRIVER_CUDA=ON"
  else
    CUDA_TARGET=""
    CUDA_DRIVER=""
  fi

  cmake -GNinja \
    -S ${SOURCE_DIR} -B ${TARGET_DIR} \
    -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
    -DCMAKE_C_COMPILER=$(which clang) -DCMAKE_CXX_COMPILER=$(which clang++) \
    ${CCACHE_CC} ${CCACHE_CXX} \
    ${IREE_LLD} \
    -DIREE_ENABLE_SPLIT_DWARF=ON ${IREE_THIN_ARCHIVES} \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \
    -DIREE_BUILD_PYTHON_BINDINGS=ON -DPython3_EXECUTABLE="$(which python)" \
    -DCMAKE_INSTALL_PREFIX=${TARGET_DIR}/install \
    ${CUDA_TARGET} ${CUDA_DRIVER} "$@"
}

iree-android-cmake() {
  if (( $# < 4 ))
  then
    echo "usage: $0 <source-dir> <target-dir> <host-dir> <build-type>"
    return 1
  fi

  SOURCE_DIR=$1; shift
  TARGET_DIR=$1; shift
  HOST_DIR=$1;   shift
  BUILD_TYPE=$1; shift

  cmake -GNinja \
    -S ${SOURCE_DIR} -B ${TARGET_DIR} \
    -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
    -DCMAKE_TOOLCHAIN_FILE="${ANDROID_NDK}/build/cmake/android.toolchain.cmake" \
    -DANDROID_ABI=arm64-v8a \
    -DANDROID_PLATFORM=android-30 \
    -DIREE_HOST_BIN_DIR="${HOST_DIR}/install/bin" \
    -DPython3_EXECUTABLE="$(which python)" \
    -DIREE_BUILD_COMPILER=OFF \
    -DIREE_BUILD_TESTS=ON \
    -DIREE_BUILD_SAMPLES=OFF "$@"
}

iree-vulkan-compile() {
  if (( $# < 3 )); then
    echo "usage: $0 <arch> <input-mlir> <output-vmfb> [<debug-log>]"
    return 1
  fi

  ARCH=$1;        shift
  SOURCE_MLIR=$1; shift
  OUTPUT_VMFB=$1; shift

  if (( $# == 1 )); then
    DEBUG_LOG=$1; shift
    $PWD/tools/iree-compile \
      --iree-hal-target-backends=vulkan \
      --iree-vulkan-target-triple=${ARCH}-unknown-unknown \
      --iree-stream-resource-max-allocation-size=4294967295 \
      --iree-stream-resource-index-bits=64 \
      --iree-vm-target-index-bits=64 \
      "${SOURCE_MLIR}" -o "${OUTPUT_VMFB}" "$@" \
      --mlir-print-ir-after-all &>! "${DEBUG_LOG}"
  else
    $PWD/tools/iree-compile \
      --iree-hal-target-backends=vulkan \
      --iree-vulkan-target-triple=${ARCH}-unknown-unknown \
      --iree-stream-resource-max-allocation-size=4294967295 \
      --iree-stream-resource-index-bits=64 \
      --iree-vm-target-index-bits=64 \
      "${SOURCE_MLIR}" -o "${OUTPUT_VMFB}" "$@"
  fi
}

iree-vulkan-rdna3-compile() {
  if (( $# < 2 )); then
    echo "usage: $0 <input-mlir> <output-vmfb> [<debug-log>]"
    return 1
  fi
  iree-vulkan-compile "rdna3" "$@"
}

iree-vulkan-ampere-compile() {
  if (( $# < 2 )); then
    echo "usage: $0 <input-mlir> <output-vmfb> [<debug-log>]"
    return 1
  fi
  iree-vulkan-compile "ampere" "$@"
}


iree-rocm-compile() {
  if (( $# < 3 )); then
    echo "usage: $0 <chip> <input-mlir> <output-vmfb> [<debug-log>]"
    return 1
  fi

  CHIP=$1;        shift
  SOURCE_MLIR=$1; shift
  OUTPUT_VMFB=$1; shift

  if (( $# == 1 )); then
    DEBUG_LOG=$1; shift
    $PWD/tools/iree-compile \
      --iree-hal-target-backends=rocm \
      --iree-rocm-target-chip=${CHIP} \
      --iree-rocm-link-bc=true \
      --iree-rocm-bc-dir=/opt/rocm/amdgcn/bitcode \
      --iree-stream-resource-max-allocation-size=4294967295 \
      --iree-stream-resource-index-bits=64 \
      --iree-vm-target-index-bits=64 \
      "${SOURCE_MLIR}" -o "${OUTPUT_VMFB}" "$@" \
      --mlir-print-ir-after-all &>! "${DEBUG_LOG}"
  else
    $PWD/tools/iree-compile \
      --iree-hal-target-backends=rocm \
      --iree-rocm-target-chip=${CHIP} \
      --iree-rocm-link-bc=true \
      --iree-rocm-bc-dir=/opt/rocm/amdgcn/bitcode \
      --iree-stream-resource-max-allocation-size=4294967295 \
      --iree-stream-resource-index-bits=64 \
      --iree-vm-target-index-bits=64 \
      "${SOURCE_MLIR}" -o "${OUTPUT_VMFB}" "$@"
  fi
}

iree-rocm-gfx1100-compile() {
  if (( $# < 2 )); then
    echo "usage: $0 <input-mlir> <output-vmfb> [<debug-log>]"
    return 1
  fi
  iree-rocm-compile "gfx1100" "$@"
}

#====== Triton ======#

triton-pip-install() {
  REPO_BASE_DIR=$(git rev-parse --show-toplevel)
  TRITON_BUILD_WITH_CCACHE=true TRITON_BUILD_WITH_CLANG_LLD=true \
    pip install ${REPO_BASE_DIR}
}

triton-print-install-version() {
  python -c "import triton; print(triton.__version__)"
}

triton-print-in-test() {
  REPO_BASE_DIR=$(git rev-parse --show-toplevel)
  if (( $# != 1 && $# != 2 )); then
    echo "usage: $0 <test-file> [<test-case>]"
    return 1
  fi
  if (( $# == 1 )); then
    MLIR_ENABLE_DUMP=1 TRITON_DISABLE_LINE_INFO=1 AMDGCN_ENABLE_DUMP=1 pytest \
      -vs ${REPO_BASE_DIR}/python/test/unit/language/test_$1.py
  else
    MLIR_ENABLE_DUMP=1 TRITON_DISABLE_LINE_INFO=1 AMDGCN_ENABLE_DUMP=1 pytest \
      -vs ${REPO_BASE_DIR}/python/test/unit/language/test_$1.py -k $2
  fi
}

triton-configure-mlir() {
  if (( $# < 3 ))
  then
    echo "usage: $0 <source-dir> <target-dir> <build-type>"
    return 1
  fi

  SOURCE_DIR=$1; shift
  TARGET_DIR=$1; shift
  BUILD_TYPE=$1; shift

  cmake -GNinja \
    -S ${SOURCE_DIR} -B ${TARGET_DIR} \
    -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \
    -DCMAKE_C_COMPILER=$(which clang) -DCMAKE_CXX_COMPILER=$(which clang++) \
    -DLLVM_ENABLE_PROJECTS="llvm;mlir" \
    -DLLVM_TARGETS_TO_BUILD="AMDGPU;NVPTX;X86;AArch64"
}

triton-cmake() {
  if (( $# < 4 ))
  then
    echo "usage: $0 <source-dir> <target-dir> <build-type> <mlir-dir>"
    return 1
  fi

  SOURCE_DIR=$1; shift
  TARGET_DIR=$1; shift
  BUILD_TYPE=$1; shift
  MLIR_DIR=$1;   shift

  if [[ "$(uname)" == "Darwin" ]]; then
    LINKER_FLAGS=()
  else
    LINKER_FLAGS=(
      "-DCMAKE_EXE_LINKER_FLAGS=-fuse-ld=lld"
      "-DCMAKE_MODULE_LINKER_FLAGS=-fuse-ld=lld"
      "-DCMAKE_SHARED_LINKER_FLAGS=-fuse-ld=lld"
    )
  fi

  REPO_BASE_DIR=$(git rev-parse --show-toplevel)

  cmake -GNinja \
    -S ${SOURCE_DIR} -B ${TARGET_DIR} \
    -DTRITON_WHEEL_DIR=${TARGET_DIR}/wheel \
    -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \
    -DTRITON_CODEGEN_BACKENDS="amd;nvidia" \
    -DLLVM_INCLUDE_DIRS=${MLIR_DIR}/include \
    -DLLVM_LIBRARY_DIR=${MLIR_DIR}/lib \
    -DLLVM_SYSPATH=${MLIR_DIR} \
    -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ \
    -DCMAKE_LINKER=lld ${LINKER_FLAGS[@]} \
    -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
    -DTRITON_BUILD_PYTHON_MODULE=ON \
    -DTRITON_BUILD_PROTON=ON \
    -DCUPTI_INCLUDE_DIR=${REPO_BASE_DIR}/third_party/nvidia/backend/include \
    -DROCTRACER_INCLUDE_DIR=${REPO_BASE_DIR}/third_party/amd/backend/include/ \
    -DJSON_INCLUDE_DIR=$HOME/.triton/json/include/
}

#====== Docker ======#

docker-build-dev-env() {
  sudo docker build . -t lei-dev-env \
    --build-arg DOCKER_USERID=$(id -u) --build-arg DOCKER_GROUPID=$(id -g) \
    --build-arg DOCKER_RENDERID=$(getent group render | cut -d: -f3)
}

docker-run-dev-env() {
  if (( $# < 1 )); then
    echo "usage: $0 <image> [<volumes>..]"
    return 1
  fi

  IMAGE=$1; shift

  if [[ -v SSH_AUTH_SOCK ]]; then
    AUTH_SOCK="--volume $SSH_AUTH_SOCK:/ssh-agent --env SSH_AUTH_SOCK=/ssh-agent"
  else
    AUTH_SOCK=""
  fi

  touch $HOME/.zsh_history
  mkdir -p $HOME/.cache/ccache
  mkdir -p $HOME/.triton

  sudo docker run -it --rm \
    --network=host --device=/dev/kfd --device=/dev/dri \
    --group-add video --group-add $(getent group render | cut -d: -f3) \
    --cap-add=SYS_PTRACE --security-opt seccomp=unconfined \
    --shm-size=16G --ulimit memlock=-1 --ulimit stack=67108864 \
    ${AUTH_SOCK} \
    --mount type=bind,source=$HOME/.zsh_history,target=/home/mirror/.zsh_history \
    -v $HOME/.cache/ccache:/ccache \
    -v $HOME/.triton:/home/mirror/.triton \
    "$@" ${IMAGE}
}
